{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TL5y5fY9Jy_x"
      },
      "source": [
        "# Binary Classification | Binær klassifikation\n",
        "\n",
        "Indtil videre har du kun oprettet regressionsmodeller. Det vil sige, at du har oprettet modeller, der producerede flydende punktprediktioner, såsom \"huse i dette område koster N tusind dollars.\" I denne vejledning vil du oprette og evaluere en binær [klassifikationsmodel](https://developers.google.com/machine-learning/glossary/#classification_model). Det vil sige, at du vil oprette en model, der besvarer en binær spørgsmål. I dette øvelse vil spørgsmålet være, \"Er huse i dette område over en bestemt pris?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuw8rRl9lNuL"
      },
      "source": [
        "## Læringsmål\n",
        "\n",
        "Efter at have gennemført denne vejledning, vil du kunne:\n",
        "\n",
        "  * Konvertere et regressionsspørgsmål til et klassifikationsspørgsmål.\n",
        "  * Ændre klassifikationsgrænsen og bestemme, hvordan denne ændring påvirker modellen.\n",
        "  * Experimentere med forskellige klassifikationsmetrikker for at bestemme modellens effektivitet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44OdC-OglN9D"
      },
      "source": [
        "## Datasættet\n",
        "\n",
        "Vores datasæt er Californien Housing Data. Som kan findes på: https://developers.google.com/machine-learning/crash-course/california-housing-data-description\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iuw6-JOGf7I"
      },
      "source": [
        "## Indlæsning af nødvendige moduler\n",
        "\n",
        "Følgende kode importerer de nødvendige moduler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "9n9_cTveKmse"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-02-19 11:09:11.739275: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1739959751.771684   23091 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1739959751.781941   23091 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-19 11:09:11.811740: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ran the import statements.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras import layers\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# The following lines adjust the granularity of reporting.\n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = \"{:.1f}\".format\n",
        "# tf.keras.backend.set_floatx('float32')\n",
        "\n",
        "print(\"Ran the import statements.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_TaJhU4KcuY"
      },
      "source": [
        "## Hent datasættet fra internettet\n",
        "\n",
        "Følgende kode celler loader de separate .csv filer og opretter følgende to pandas DataFrames:\n",
        "\n",
        "* `train_df`, som indeholder træningssættet\n",
        "* `test_df`, som indeholder test sættet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JZlvdpyYKx7V"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\")\n",
        "test_df = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_test.csv\")\n",
        "train_df = train_df.reindex(np.random.permutation(train_df.index)) # shuffle the training set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_G6y-XcEmk6r"
      },
      "source": [
        "## Normalisering af datasættet\n",
        "\n",
        "Når du opretter en model med flere funktioner, skal værdierne for hver funktion dække omtrent samme område. For eksempel, hvis et område har en værdi på 500 til 100.000 og et andet område har en værdi på 2 til 12, så vil modellen være svær at træne. Derfor skal du\n",
        "[normalisere](https://developers.google.com/machine-learning/glossary/#normalization) funktioner i en model med flere funktioner.\n",
        "\n",
        "\n",
        "Følgende kode normaliserer datasættene ved at konvertere hver rå værdi (inklusive labelen) til sin Z-score. En **Z-score** er antallet af standardafvigelser fra middelværdien for en bestemt rå værdi. For eksempel, overvej en funktion, der har følgende karakteristika:\n",
        "\n",
        "\n",
        "  * Middelværdien er 60.\n",
        "  * Standardafvigelsen er 10.\n",
        "\n",
        "\n",
        "Den rå værdi 75 ville have en Z-score på +1.5:\n",
        "\n",
        "\n",
        "```\n",
        "  Z-score = (75 - 60) / 10 = +1.5\n",
        "```\n",
        "\n",
        "Den rå værdi 38 ville have en Z-score på -2.2:\n",
        "\n",
        "```\n",
        "  Z-score = (38 - 60) / 10 = -2.2\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "n7nuAHoZIgVI"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7217</th>\n",
              "      <td>0.6</td>\n",
              "      <td>-0.8</td>\n",
              "      <td>0.7</td>\n",
              "      <td>-0.9</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.9</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.1</td>\n",
              "      <td>-0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>235</th>\n",
              "      <td>1.5</td>\n",
              "      <td>-0.9</td>\n",
              "      <td>-1.2</td>\n",
              "      <td>2.8</td>\n",
              "      <td>3.2</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>-0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15731</th>\n",
              "      <td>-1.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8450</th>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.7</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1847</th>\n",
              "      <td>1.1</td>\n",
              "      <td>-1.2</td>\n",
              "      <td>-1.7</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.4</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>1.4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "7217         0.6      -0.8                 0.7         -0.9            -1.0   \n",
              "235          1.5      -0.9                -1.2          2.8             3.2   \n",
              "15731       -1.4       1.0                 1.9         -0.5            -0.4   \n",
              "8450         0.5      -0.7                -0.4          0.1             0.8   \n",
              "1847         1.1      -1.2                -1.7          0.5             0.5   \n",
              "\n",
              "       population  households  median_income  median_house_value  \n",
              "7217         -0.9        -1.0            1.1                -0.4  \n",
              "235          -0.1         0.5           -0.1                -0.5  \n",
              "15731        -0.1        -0.4           -0.5                 0.3  \n",
              "8450          0.7         0.7           -0.6                -0.1  \n",
              "1847          0.2         0.4           -0.4                 1.4  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calculate the Z-scores of each column in the training set and\n",
        "# write those Z-scores into a new pandas DataFrame named train_df_norm.\n",
        "train_df_mean = train_df.mean()\n",
        "train_df_std = train_df.std()\n",
        "train_df_norm = (train_df - train_df_mean)/train_df_std\n",
        "\n",
        "# Examine some of the values of the normalized training set. Notice that most\n",
        "# Z-scores fall between -2 and +2.\n",
        "train_df_norm.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QoW-59jVFF2I"
      },
      "outputs": [],
      "source": [
        "# Calculate the Z-scores of each column in the test set and\n",
        "# write those Z-scores into a new pandas DataFrame named test_df_norm.\n",
        "test_df_norm = (test_df - train_df_mean) / train_df_std\n",
        "\n",
        "# Note that we transform the test data with the values calculated from the training set,\n",
        "# as you should always transform your datasets with exactly the same values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-swmXtWnZGis"
      },
      "source": [
        "## Opgave 1: Opret en binær label\n",
        "\n",
        "I klassifikationsproblemer skal labelen for hver eksempel være enten 0 eller 1. Desværre indeholder den naturlige label i Californien Housing Datasættet, `median_house_value`, floating-point værdier som 80.100 eller 85.700 i stedet for 0'er og 1'er, mens den normaliserede version af `median_house_values` indeholder floating-point værdier primært mellem -3 og +3.\n",
        "\n",
        "\n",
        "Din opgave er at oprette en ny kolonne med navnet `median_house_value_is_high` i både træningssættet og testsættet. Hvis `median_house_value` er højere end en bestemt vilkårlig værdi (defineret af `threshold`), så sæt `median_house_value_is_high` til 1. Ellers sæt `median_house_value_is_high` til 0.\n",
        "\n",
        "\n",
        "**Hint:** Cellerne i `median_house_value_is_high` kolonnen skal hver isætte `1` og `0`, ikke `True` og `False`. For at konvertere `True` og `False` til `1` og `0`, kalder du pandas DataFrame funktionen `astype(float)`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "d4kWfWA8bhKW"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7217    0.0\n",
              "235     0.0\n",
              "15731   0.0\n",
              "8450    0.0\n",
              "1847    0.0\n",
              "         ..\n",
              "9372    0.0\n",
              "8955    0.0\n",
              "726     0.0\n",
              "3859    0.0\n",
              "15844   0.0\n",
              "Name: median_house_value_is_high, Length: 8000, dtype: float64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "threshold = 265000 # This is the 75th percentile for median house values.\n",
        "train_df_norm[\"median_house_value_is_high\"] = train_df_norm[\"median_house_value\"].gt(threshold).astype(float)\n",
        "test_df_norm[\"median_house_value_is_high\"] = test_df_norm[\"median_house_value\"].gt(threshold).astype(float)\n",
        "\n",
        "# Print out a few example cells from the beginning and\n",
        "# middle of the training set, just to make sure that\n",
        "# your code created only 0s and 1s in the newly created\n",
        "# median_house_value_is_high column\n",
        "train_df_norm[\"median_house_value_is_high\"].head(8000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kir8UTUXSV8"
      },
      "source": [
        "## Reprensentere funktioner som inputlag\n",
        "\n",
        "Denne kode celle specificerer funktionerne, `median_income` og ` total_rooms`, som du vil træne modellen på. Disse [Input](https://www.tensorflow.org/api_docs/python/tf/keras/Input) objekter er instansieret som Keras tensors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3tmmZIDw4JEC"
      },
      "outputs": [],
      "source": [
        "inputs = {\n",
        "# Features used to train the model on.\n",
        "  'median_income': tf.keras.Input(shape=(1,)),\n",
        "  'total_rooms': tf.keras.Input(shape=(1,))\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3014ezH3C7jT"
      },
      "source": [
        "## Definere funktioner, der bygger og træner en model\n",
        "\n",
        "Denne kode celle definerer to funktioner: \n",
        "\n",
        "  * `create_model(inputs, learning_rate, METRICS)`, som definerer modellens\n",
        "    topografi.\n",
        "\n",
        "  * `train_model(model, dataset, epochs, label_name, batch_size, shuffle)`, bruger input funktioner og labels til at træne modellen.\n",
        "\n",
        "I dette øvelseseksempel bruger vi [sigmoid](https://developers.google.com/machine-learning/glossary#sigmoid-function) som aktiveringsfunktion.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pedD5GhlDC-y"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defined the create_model and train_model functions.\n"
          ]
        }
      ],
      "source": [
        "def create_model(my_inputs, my_learning_rate, METRICS):\n",
        "  # Use a Concatenate layer to concatenate the input layers into a single tensor.\n",
        "  # as input for the Dense layer. Ex: [input_1[0][0], input_2[0][0]]\n",
        "  concatenated_inputs = tf.keras.layers.Concatenate()(my_inputs.values())\n",
        "  dense = layers.Dense(units=1, name='dense_layer', activation=tf.sigmoid)\n",
        "  dense_output = dense(concatenated_inputs)\n",
        "  \"\"\"Create and compile a simple classification model.\"\"\"\n",
        "  my_outputs = {\n",
        "    'dense': dense_output,\n",
        "  }\n",
        "  model = tf.keras.Model(inputs=my_inputs, outputs=my_outputs)\n",
        "\n",
        "  # Call the compile method to construct the layers into a model that\n",
        "  # TensorFlow can execute.  Notice that we're using a different loss\n",
        "  # function for classification than for regression.\n",
        "  model.compile(optimizer=tf.keras.optimizers.experimental.RMSprop(learning_rate=my_learning_rate),\n",
        "                loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                metrics=METRICS)\n",
        "  return model\n",
        "\n",
        "\n",
        "def train_model(model, dataset, epochs, label_name,\n",
        "                batch_size=None, shuffle=True):\n",
        "  \"\"\"Feed a dataset into the model in order to train it.\"\"\"\n",
        "\n",
        "  # The x parameter of tf.keras.Model.fit can be a list of arrays, where\n",
        "  # each array contains the data for one feature.  Here, we're passing\n",
        "  # every column in the dataset. Note that the feature_layer will filter\n",
        "  # away most of those columns, leaving only the desired columns and their\n",
        "  # representations as features.\n",
        "  features = {name:np.array(value) for name, value in dataset.items()}\n",
        "  label = np.array(features.pop(label_name))\n",
        "  history = model.fit(x=features, y=label, batch_size=batch_size,\n",
        "                      epochs=epochs, shuffle=shuffle)\n",
        "\n",
        "  # The list of epochs is stored separately from the rest of history.\n",
        "  epochs = history.epoch\n",
        "\n",
        "  # Isolate the classification metric for each epoch.\n",
        "  hist = pd.DataFrame(history.history)\n",
        "\n",
        "  return epochs, hist\n",
        "\n",
        "print(\"Defined the create_model and train_model functions.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ak_TMAzGOIFq"
      },
      "source": [
        "## Definere en plotting funktion\n",
        "\n",
        "Denne [matplotlib](https://developers.google.com/machine-learning/glossary/#matplotlib) funktion plotter en eller flere kurver, der viser, hvordan forskellige klassifikationsmålinger ændrer sig med hver epoch.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "cellView": "form",
        "id": "QF0BFRXTOeR3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defined the plot_curve function.\n"
          ]
        }
      ],
      "source": [
        "def plot_curve(epochs, hist, list_of_metrics):\n",
        "  \"\"\"Plot a curve of one or more classification metrics vs. epoch.\"\"\"\n",
        "  # list_of_metrics should be one of the names shown in:\n",
        "  # https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#define_the_model_and_metrics\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Value\")\n",
        "\n",
        "  for m in list_of_metrics:\n",
        "    x = hist[m]\n",
        "    plt.plot(epochs[1:], x[1:], label=m)\n",
        "\n",
        "  plt.legend()\n",
        "\n",
        "print(\"Defined the plot_curve function.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-IXYVfvM4gD"
      },
      "source": [
        "## Kald funktionerne til at oprette og træne modellen, og derefter plotte resultaterne.\n",
        "\n",
        "Denne kode celle specificerer hyperparametrene, og derefter kalder funktionerne til at oprette og træne modellen, og derefter plotte resultaterne."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "nj3v5EKQFY8s"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Only input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: dict_values([<KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=keras_tensor>, <KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=keras_tensor_1>]) (of type <class 'dict_values'>)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 15\u001b[0m\n\u001b[1;32m      9\u001b[0m METRICS \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     10\u001b[0m            tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mBinaryAccuracy(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m                                            threshold\u001b[38;5;241m=\u001b[39mclassification_threshold),\n\u001b[1;32m     12\u001b[0m           ]\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Establish the model's topography.\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m my_model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMETRICS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# To view a PNG of this model's layers, uncomment the call to\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# `tf.keras.utils.plot_model` below. After running this code cell, click\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# the file folder on the left, then the `my_classification_model.png` file.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# tf.keras.utils.plot_model(my_model, \"my_classification_model.png\")\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Train the model on the training set.\u001b[39;00m\n\u001b[1;32m     23\u001b[0m epochs, hist \u001b[38;5;241m=\u001b[39m train_model(my_model, train_df_norm, epochs,\n\u001b[1;32m     24\u001b[0m                            label_name, batch_size)\n",
            "Cell \u001b[0;32mIn[9], line 4\u001b[0m, in \u001b[0;36mcreate_model\u001b[0;34m(my_inputs, my_learning_rate, METRICS)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate_model\u001b[39m(my_inputs, my_learning_rate, METRICS):\n\u001b[1;32m      2\u001b[0m   \u001b[38;5;66;03m# Use a Concatenate layer to concatenate the input layers into a single tensor.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m   \u001b[38;5;66;03m# as input for the Dense layer. Ex: [input_1[0][0], input_2[0][0]]\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m   concatenated_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m   dense \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mDense(units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdense_layer\u001b[39m\u001b[38;5;124m'\u001b[39m, activation\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39msigmoid)\n\u001b[1;32m      6\u001b[0m   dense_output \u001b[38;5;241m=\u001b[39m dense(concatenated_inputs)\n",
            "File \u001b[0;32m/usr/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m/usr/lib/python3.13/site-packages/keras/src/layers/layer.py:789\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mflatten(args):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    785\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, KerasTensor)\n\u001b[1;32m    786\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mis_tensor(arg)\n\u001b[1;32m    787\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m arg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    788\u001b[0m         ):\n\u001b[0;32m--> 789\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    790\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly input tensors may be passed as \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    791\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositional arguments. The following argument value \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    792\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshould be passed as a keyword argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    793\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(arg)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    794\u001b[0m             )\n\u001b[1;32m    796\u001b[0m \u001b[38;5;66;03m# Caches info about `call()` signature, args, kwargs.\u001b[39;00m\n\u001b[1;32m    797\u001b[0m call_spec \u001b[38;5;241m=\u001b[39m CallSpec(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_signature, args, kwargs)\n",
            "\u001b[0;31mValueError\u001b[0m: Only input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: dict_values([<KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=keras_tensor>, <KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=keras_tensor_1>]) (of type <class 'dict_values'>)"
          ]
        }
      ],
      "source": [
        "# The following variables are the hyperparameters.\n",
        "learning_rate = 0.001\n",
        "epochs = 20\n",
        "batch_size = 100\n",
        "label_name = \"median_house_value_is_high\"\n",
        "classification_threshold = 0.35\n",
        "\n",
        "# Establish the metrics the model will measure.\n",
        "METRICS = [\n",
        "           tf.keras.metrics.BinaryAccuracy(name='accuracy',\n",
        "                                           threshold=classification_threshold),\n",
        "          ]\n",
        "\n",
        "# Establish the model's topography.\n",
        "my_model = create_model(inputs, learning_rate, METRICS)\n",
        "\n",
        "# To view a PNG of this model's layers, uncomment the call to\n",
        "# `tf.keras.utils.plot_model` below. After running this code cell, click\n",
        "# the file folder on the left, then the `my_classification_model.png` file.\n",
        "# tf.keras.utils.plot_model(my_model, \"my_classification_model.png\")\n",
        "\n",
        "# Train the model on the training set.\n",
        "epochs, hist = train_model(my_model, train_df_norm, epochs,\n",
        "                           label_name, batch_size)\n",
        "\n",
        "# Plot a graph of the metric(s) vs. epochs.\n",
        "list_of_metrics_to_plot = ['accuracy']\n",
        "\n",
        "plot_curve(epochs, hist, list_of_metrics_to_plot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF64TpqkbOpn"
      },
      "source": [
        "Accuracy skal gradvist blive bedre under træningen (indtil det ikke kan forbedres yderligere).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xNqWWos_zyk"
      },
      "source": [
        "## Evaluer modellen mod test sættet\n",
        "\n",
        "Efter at have trænet modellen, fik du en vis præcision mod *træningssættet*. Kald følgende kode celle for at bestemme din modelens præcision mod *test sættet*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJorkMlDmtHf"
      },
      "outputs": [],
      "source": [
        "features = {name:np.array(value) for name, value in test_df_norm.items()}\n",
        "label = np.array(features.pop(label_name))\n",
        "\n",
        "my_model.evaluate(x = features, y = label, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7cHkFXalXV5"
      },
      "source": [
        "## Opgave 2: Hvor præcis er din model?\n",
        "\n",
        "Er din model værdifuld? Giv dit svar herunder:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8crSCCVf6gm"
      },
      "source": [
        "## Opgave 3: Tilføj precision og recall som målinger\n",
        "\n",
        "At bruge accuracy, isoleret set, kan være en dårlig måde at vurdere en klassifikationsmodel på. Modificer koden i følgende kode celle for at gøre modellen til at måle ikke kun accuracy, men også precision og recall. Vi har tilføjet accuracy og precision; din opgave er at tilføje recall. Se [TensorFlow Reference](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Recall) for detaljer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-k1MD2XArmO"
      },
      "outputs": [],
      "source": [
        "# The following variables are the hyperparameters.\n",
        "learning_rate = 0.001\n",
        "epochs = 20\n",
        "batch_size = 100\n",
        "classification_threshold = 0.35\n",
        "label_name = \"median_house_value_is_high\"\n",
        "\n",
        "# Modify the following definition of METRICS to generate\n",
        "# not only accuracy and precision, but also recall:\n",
        "METRICS = [\n",
        "      tf.keras.metrics.BinaryAccuracy(name='accuracy',\n",
        "                                      threshold=classification_threshold),\n",
        "      tf.keras.metrics.Precision(thresholds=classification_threshold,\n",
        "                                 name='precision'\n",
        "                                 ),\n",
        "      ?  # write code here\n",
        "]\n",
        "\n",
        "# Establish the model's topography.\n",
        "my_model = create_model(inputs, learning_rate, METRICS)\n",
        "\n",
        "# Train the model on the training set.\n",
        "epochs, hist = train_model(my_model, train_df_norm, epochs,\n",
        "                           label_name, batch_size)\n",
        "\n",
        "# Plot metrics vs. epochs\n",
        "list_of_metrics_to_plot = ['accuracy', 'precision', 'recall']\n",
        "plot_curve(epochs, hist, list_of_metrics_to_plot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAsB85iKSXLe"
      },
      "source": [
        "## Opgave 4: Eksperimenter med klassifikationsgrænsen (Hvis du har ekstra tid)\n",
        "\n",
        "Eksperimenter med forskellige værdier for `classification_threshold` i koden i cellen \"Invoke the creating, training, and plotting functions.\"  Hvilken værdi for `classification_threshold` producerer den højeste præcision?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FLPDYI7Sphnj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBGRS0Ndduus"
      },
      "source": [
        "## Opgave 5: Opsummere modellens ydeevne (Hvis du har ekstra tid)\n",
        "\n",
        "Hvis du har ekstra tid, tilføj en anden måling, der forsøger at opsummere modellens samlede ydeevne.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "vwNE6syoFvWe"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Binary Classification.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
